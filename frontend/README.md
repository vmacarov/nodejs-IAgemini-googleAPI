ğŸ§  FullStack Chat con Gemini

Una aplicaciÃ³n de chat FullStack construida con React + Vite en el frontend y Express.js en el backend, utilizando la API de Gemini (Google Generative AI) para generar respuestas de inteligencia artificial.

ğŸš€ CaracterÃ­sticas

Interfaz moderna y responsiva
ConversaciÃ³n estilo "chat" entre usuario e IA
Backend seguro: la API key de Gemini no se expone al cliente
Historial de mensajes alternado tipo:

Usuario
IA
Usuario
IA

ğŸ“¦ TecnologÃ­as

Frontend: React + Vite + CSS
Backend: Node.js + Express
IA: Gemini API (@google/generative-ai)

ğŸ› ï¸ Requisitos

Node.js >= 18
Una clave API de Gemini (desde Google AI Studio)

ğŸ”§ InstalaciÃ³n

1. Clonar el repositorio

git clone https://github.com/vmacarov/nodejs-IAgemini-googleAPI.git
cd fullstack-gemini-chat

2. InstalÃ¡ dependencias del backend:

cd backend
npm install

3. InstalÃ¡ dependencias del frontend:
cd frontend
npm install

ğŸ” ConfiguraciÃ³n del entorno

VolvÃ© al directorio raÃ­z y CreÃ¡ un archivo .env en el directorio raÃ­z del proyecto con el siguiente contenido:

GEMINI_API_KEY=tu_clave_de_api

â–¶ï¸ EjecuciÃ³n

sobre el directorio backend
Iniciar el backend (escucha en el puerto 8000) ejecutar:
node index.js
AplicaciÃ³n disponible en: http://localhost:8000

En otra terminal, iniciar el frontend sobre el directorio frontend:
npm run dev
AplicaciÃ³n disponible en: http://localhost:5173

ğŸ§‘â€ğŸ’» Uso

1.EscribÃ­ un mensaje en el campo de entrada.
2.PresionÃ¡ Enter o hacÃ© clic en Enviar.
3.El mensaje se envÃ­a al servidor, que lo reenvÃ­a a la API de Gemini.
4.La respuesta de la IA aparece justo debajo de tu mensaje.

ğŸ›¡ Seguridad

La API Key de Gemini no se expone al cliente.
Las solicitudes se hacen desde el servidor backend, que actÃºa como proxy seguro.